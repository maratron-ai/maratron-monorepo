"""Integration tests for Advanced MCP Tools.

These tests verify that all new MCP tools work correctly through the complete
three-phase function calling architecture (Planning → Execution → Synthesis)
and integrate properly with the chat interface.
"""

import pytest
import asyncio
import json
from datetime import datetime, timedelta
from unittest.mock import AsyncMock, MagicMock, patch

# Import all tool modules for testing
from maratron_ai import advanced_tools
from maratron_ai import health_recovery_tools
from maratron_ai import route_environment_tools  
from maratron_ai import equipment_gear_tools
from maratron_ai import competition_racing_tools


class TestHealthRecoveryIntegration:
    """Integration tests for Health & Recovery tools."""

    @pytest.fixture
    def mock_user_context(self):
        """Mock user context for integration tests."""
        with patch('maratron_ai.user_context.context.get_current_user_id') as mock_user, \
             patch('maratron_ai.security.data_isolation.get_current_user_id') as mock_user_2, \
             patch('maratron_ai.user_context.context.get_current_user_session') as mock_session:
            mock_user.return_value = 'integration-test-user'
            mock_user_2.return_value = 'integration-test-user'
            mock_session.return_value = {
                'user_id': 'integration-test-user',
                'session_id': 'integration-test-session',
                'started_at': datetime.now()
            }
            yield mock_user

    @pytest.fixture
    def mock_database(self):
        """Mock database with realistic data for integration testing."""
        pool = AsyncMock()
        
        # Mock user data
        user_data = {
            'id': 'integration-test-user',
            'name': 'Integration Test Runner',
            'age': 30,
            'trainingLevel': 'intermediate',
            'weeklyMileage': 35,
            'VDOT': 45,
            'injuryHistory': json.dumps(['shin_splints_2023'])
        }
        
        # Mock recent runs with varying intensities
        recent_runs = []
        for i in range(20):
            recent_runs.append({
                'distance': 5.0 + (i % 8),
                'duration': f'00:{40 + i*2}:00',
                'date': datetime.now() - timedelta(days=i*2),
                'notes': 'Good run' if i % 3 == 0 else None,
                'elevationGain': 100 + (i * 15)
            })
        
        pool.fetchrow.return_value = user_data
        pool.fetch.return_value = recent_runs
        pool.execute.return_value = None
        
        with patch('maratron_ai.health_recovery_tools.get_pool', return_value=pool), \
             patch('maratron_ai.route_environment_tools.get_pool', return_value=pool), \
             patch('maratron_ai.equipment_gear_tools.get_pool', return_value=pool), \
             patch('maratron_ai.competition_racing_tools.get_pool', return_value=pool), \
             patch('maratron_ai.advanced_tools.get_pool', return_value=pool):
            yield pool

    @pytest.mark.integration
    async def test_health_recovery_workflow(self, mock_user_context, mock_database):
        """Test complete health and recovery analysis workflow."""
        
        # 1. Analyze injury risk
        injury_risk = await health_recovery_tools.analyze_injury_risk_tool('4weeks')
        assert "Injury Risk Analysis (4weeks)" in injury_risk
        assert "Risk Factors" in injury_risk or "Low" in injury_risk
        
        # 2. Get recovery recommendations
        recovery_recs = await health_recovery_tools.get_recovery_recommendations_tool('general')
        assert "Recovery Recommendations (General)" in recovery_recs
        assert "Training Load Assessment" in recovery_recs
        
        # 3. Analyze training load
        training_load = await health_recovery_tools.analyze_training_load_tool('4weeks')
        assert "Training Load Analysis (4weeks)" in training_load
        assert "Load Progression" in training_load
        
        # 4. Get comprehensive health insights
        health_insights = await health_recovery_tools.get_health_insights_tool()
        assert "Comprehensive Health Insights" in health_insights
        assert "Training Status" in health_insights

    @pytest.mark.integration
    async def test_route_environment_workflow(self, mock_user_context, mock_database):
        """Test complete route and environment optimization workflow."""
        
        # 1. Analyze environment impact
        env_impact = await route_environment_tools.analyze_environment_impact_tool('4weeks')
        assert "Environment Impact Analysis (4weeks)" in env_impact
        
        # 2. Get route recommendations
        route_recs = await route_environment_tools.get_route_recommendations_tool('speed', 5.0, 'hot')
        assert "Route Recommendations" in route_recs
        assert "Goal: Speed training" in route_recs
        
        # 3. Analyze elevation impact
        elevation_impact = await route_environment_tools.analyze_elevation_impact_tool()
        assert "Elevation Impact Analysis" in elevation_impact
        
        # 4. Get seasonal advice
        seasonal_advice = await route_environment_tools.get_seasonal_training_advice_tool('current')
        assert "Seasonal Training Guide" in seasonal_advice
        
        # 5. Optimize training environment
        env_optimization = await route_environment_tools.optimize_training_environment_tool()
        assert "Training Environment Optimization" in env_optimization

    @pytest.mark.integration
    async def test_equipment_gear_workflow(self, mock_user_context, mock_database):
        """Test complete equipment and gear management workflow."""
        
        # Mock shoes data for equipment tools
        shoes_data = [
            {
                'name': 'Nike Pegasus',
                'currentDistance': 200.0,
                'maxDistance': 400.0,
                'retired': False,
                'createdAt': datetime.now() - timedelta(days=60)
            },
            {
                'name': 'Brooks Ghost',
                'currentDistance': 350.0,
                'maxDistance': 400.0,
                'retired': False,
                'createdAt': datetime.now() - timedelta(days=120)
            }
        ]
        
        # Override shoes query for this test
        mock_database.fetch.return_value = shoes_data
        
        # 1. Analyze shoe rotation
        shoe_rotation = await equipment_gear_tools.analyze_shoe_rotation_tool()
        assert "Shoe Rotation Analysis" in shoe_rotation
        assert "Your Collection" in shoe_rotation
        
        # 2. Get gear recommendations
        gear_recs = await equipment_gear_tools.get_gear_recommendations_tool('racing', 'summer')
        assert "Gear Recommendations - Racing (Summer)" in gear_recs
        
        # 3. Track equipment maintenance
        maintenance = await equipment_gear_tools.track_equipment_maintenance_tool('shoes')
        assert "Equipment Maintenance Tracker (Shoes)" in maintenance
        
        # 4. Optimize gear selection
        gear_selection = await equipment_gear_tools.optimize_gear_selection_tool('tempo', 6.0)
        assert "Gear Selection for Tempo Run (6.0 miles)" in gear_selection
        
        # 5. Plan equipment lifecycle
        lifecycle = await equipment_gear_tools.plan_equipment_lifecycle_tool()
        assert "Equipment Lifecycle Planning" in lifecycle

    @pytest.mark.integration
    async def test_competition_racing_workflow(self, mock_user_context, mock_database):
        """Test complete competition and racing strategy workflow."""
        
        # 1. Create race strategy
        race_strategy = await competition_racing_tools.create_race_strategy_tool(
            13.1, '1:45:00', '2024-10-15', 'road'
        )
        assert "Race Strategy Planning" in race_strategy
        assert "13.1 miles" in race_strategy
        
        # 2. Analyze race readiness
        race_readiness = await competition_racing_tools.analyze_race_readiness_tool(
            13.1, '2024-10-15'
        )
        assert "Race Readiness Analysis" in race_readiness
        
        # 3. Benchmark performance
        performance_benchmark = await competition_racing_tools.benchmark_performance_tool('1year')
        assert "Performance Benchmarking (1year)" in performance_benchmark
        
        # 4. Plan race calendar
        race_calendar = await competition_racing_tools.plan_race_calendar_tool('fall', 'half')
        assert "Race Calendar Planning" in race_calendar
        
        # 5. Analyze post-race performance
        post_race = await competition_racing_tools.analyze_post_race_performance_tool(
            13.1, '1:42:00', '2024-09-15', 'maximum'
        )
        assert "Post-Race Performance Analysis" in post_race

    @pytest.mark.integration
    async def test_advanced_training_workflow(self, mock_user_context, mock_database):
        """Test advanced training and analytics workflow."""
        
        # 1. Generate training plan
        training_plan = await advanced_tools.generate_training_plan_tool(
            'race', 13.1, '1:45:00', 16, 'miles'
        )
        assert "Training Plan Generated Successfully!" in training_plan
        
        # 2. Get performance trends
        performance_trends = await advanced_tools.get_performance_trends_tool('3months')
        assert "Performance Trends (3months)" in performance_trends
        
        # 3. Predict race time
        race_prediction = await advanced_tools.predict_race_time_tool(
            26.2, '2024-11-15', 'miles'
        )
        assert "Race Time Prediction" in race_prediction
        
        # 4. Set and track goals
        goal_setting = await advanced_tools.set_running_goal_tool(
            'race_time', 105, '2024-10-15', 'Sub 1:45 half marathon'
        )
        assert "Goal Set Successfully!" in goal_setting


class TestChatIntegrationFlow:
    """Test that all tools work through the chat interface."""

    @pytest.fixture
    def mock_chat_environment(self):
        """Mock the complete chat environment."""
        with patch('maratron_ai.user_context.context.get_current_user_id') as mock_user, \
             patch('maratron_ai.security.data_isolation.get_current_user_id') as mock_user_2:
            mock_user.return_value = 'chat-test-user'
            mock_user_2.return_value = 'chat-test-user'
            yield

    @pytest.mark.integration
    @pytest.mark.slow
    async def test_all_tools_accessible_via_chat(self, mock_chat_environment):
        """Verify all 28 MCP tools are properly integrated and accessible."""
        
        # Import the chat handler tool definitions
        try:
            from maratron_ai.server import (
                # Core tools (already tested)
                get_smart_user_context,
                get_user_runs,
                add_run,
                analyze_user_patterns,
                get_motivational_context,
                update_conversation_intelligence,
                add_shoe,
                get_database_summary,
                get_user_shoes,
                
                # Advanced training tools
                generate_training_plan,
                get_active_training_plan,
                set_running_goal,
                get_goal_progress,
                get_performance_trends,
                predict_race_time,
                get_social_feed,
                create_run_post,
                
                # Health & Recovery tools
                analyze_injury_risk,
                get_recovery_recommendations,
                analyze_training_load,
                get_health_insights,
                
                # Route & Environment tools
                analyze_environment_impact,
                get_route_recommendations,
                analyze_elevation_impact,
                get_seasonal_training_advice,
                optimize_training_environment,
                
                # Equipment & Gear tools
                analyze_shoe_rotation,
                get_gear_recommendations,
                track_equipment_maintenance,
                optimize_gear_selection,
                plan_equipment_lifecycle,
                
                # Competition & Racing tools
                create_race_strategy,
                analyze_race_readiness,
                benchmark_performance,
                plan_race_calendar,
                analyze_post_race_performance
            )
            
            # Verify all tools are callable functions
            all_tools = [
                get_smart_user_context, get_user_runs, add_run, analyze_user_patterns,
                get_motivational_context, update_conversation_intelligence, add_shoe,
                get_database_summary, get_user_shoes, generate_training_plan,
                get_active_training_plan, set_running_goal, get_goal_progress,
                get_performance_trends, predict_race_time, get_social_feed,
                create_run_post, analyze_injury_risk, get_recovery_recommendations,
                analyze_training_load, get_health_insights, analyze_environment_impact,
                get_route_recommendations, analyze_elevation_impact, get_seasonal_training_advice,
                optimize_training_environment, analyze_shoe_rotation, get_gear_recommendations,
                track_equipment_maintenance, optimize_gear_selection, plan_equipment_lifecycle,
                create_race_strategy, analyze_race_readiness, benchmark_performance,
                plan_race_calendar, analyze_post_race_performance
            ]
            
            # Verify we have all 37 tools (9 core + 28 new)
            assert len(all_tools) == 37
            
            # Verify all are callable
            for tool in all_tools:
                assert callable(tool), f"Tool {tool.__name__} is not callable"
                
        except ImportError as e:
            pytest.fail(f"Failed to import MCP tools from server: {e}")

    @pytest.mark.integration
    async def test_tool_categories_comprehensive(self):
        """Test that each tool category has comprehensive coverage."""
        
        # Health & Recovery: 4 tools
        health_tools = [
            'analyze_injury_risk',
            'get_recovery_recommendations', 
            'analyze_training_load',
            'get_health_insights'
        ]
        
        # Route & Environment: 5 tools
        route_tools = [
            'analyze_environment_impact',
            'get_route_recommendations',
            'analyze_elevation_impact', 
            'get_seasonal_training_advice',
            'optimize_training_environment'
        ]
        
        # Equipment & Gear: 5 tools
        equipment_tools = [
            'analyze_shoe_rotation',
            'get_gear_recommendations',
            'track_equipment_maintenance',
            'optimize_gear_selection',
            'plan_equipment_lifecycle'
        ]
        
        # Competition & Racing: 5 tools
        racing_tools = [
            'create_race_strategy',
            'analyze_race_readiness',
            'benchmark_performance',
            'plan_race_calendar',
            'analyze_post_race_performance'
        ]
        
        # Advanced Training: 8 tools
        training_tools = [
            'generate_training_plan',
            'get_active_training_plan',
            'set_running_goal',
            'get_goal_progress',
            'get_performance_trends',
            'predict_race_time',
            'get_social_feed',
            'create_run_post'
        ]
        
        # Core tools: 9 tools
        core_tools = [
            'get_smart_user_context',
            'get_user_runs',
            'add_run',
            'analyze_user_patterns',
            'get_motivational_context',
            'update_conversation_intelligence',
            'add_shoe',
            'get_database_summary',
            'get_user_shoes'
        ]
        
        # Verify total count: 4 + 5 + 5 + 5 + 8 + 9 = 36 tools
        # (Note: This accounts for the core tools that existed before)
        total_new_tools = len(health_tools) + len(route_tools) + len(equipment_tools) + len(racing_tools) + len(training_tools)
        assert total_new_tools == 27  # 27 new advanced tools + 9 existing core = 36 total
        
        # Verify each category has meaningful coverage
        assert len(health_tools) >= 4, "Health category should have at least 4 tools"
        assert len(route_tools) >= 5, "Route category should have at least 5 tools"
        assert len(equipment_tools) >= 5, "Equipment category should have at least 5 tools" 
        assert len(racing_tools) >= 5, "Racing category should have at least 5 tools"


class TestEndToEndScenarios:
    """Test realistic end-to-end user scenarios."""

    @pytest.fixture
    def realistic_user_setup(self):
        """Setup a realistic user scenario."""
        with patch('maratron_ai.user_context.context.get_current_user_id') as mock_user, \
             patch('maratron_ai.security.data_isolation.get_current_user_id') as mock_user_2:
            mock_user.return_value = 'scenario-test-user'
            mock_user_2.return_value = 'scenario-test-user'
            
            # Mock realistic database responses
            pool = AsyncMock()
            
            # Marathon training user
            user_data = {
                'id': 'scenario-test-user',
                'name': 'Marathon Trainee',
                'age': 32,
                'trainingLevel': 'intermediate',
                'weeklyMileage': 45,
                'VDOT': 48,
                'goals': json.dumps([{
                    'goal_type': 'race_time',
                    'target_value': 180,  # 3:00:00 marathon
                    'target_date': '2024-11-03',
                    'description': 'Sub-3 marathon'
                }])
            }
            
            pool.fetchrow.return_value = user_data
            
            with patch('maratron_ai.health_recovery_tools.get_pool', return_value=pool), \
                 patch('maratron_ai.route_environment_tools.get_pool', return_value=pool), \
                 patch('maratron_ai.equipment_gear_tools.get_pool', return_value=pool), \
                 patch('maratron_ai.competition_racing_tools.get_pool', return_value=pool), \
                 patch('maratron_ai.advanced_tools.get_pool', return_value=pool):
                yield pool

    @pytest.mark.integration
    @pytest.mark.slow
    async def test_marathon_training_scenario(self, realistic_user_setup):
        """Test a complete marathon training scenario."""
        
        # Marathon trainee wants comprehensive preparation
        mock_database = realistic_user_setup
        
        # Marathon training runs
        training_runs = []
        for week in range(16):  # 16-week marathon plan
            for day in range(7):
                if day in [0, 2, 4, 6]:  # 4 runs per week
                    distance = 6 if day != 6 else min(12 + week, 20)  # Long run progression
                    training_runs.append({
                        'distance': distance,
                        'duration': f'0{distance//10 + 1}:{(distance*8)%60:02d}:00',
                        'date': datetime.now() - timedelta(days=week*7 + day),
                        'elevationGain': 50 + (distance * 5)
                    })
        
        mock_database.fetch.return_value = training_runs
        
        # 1. Create marathon race strategy
        race_strategy = await competition_racing_tools.create_race_strategy_tool(
            26.2, '3:00:00', '2024-11-03', 'road'
        )
        assert "Race Strategy Planning" in race_strategy
        assert "26.2 miles" in race_strategy
        
        # 2. Analyze injury risk during high-volume training
        injury_analysis = await health_recovery_tools.analyze_injury_risk_tool('8weeks')
        assert "Injury Risk Analysis" in injury_analysis
        
        # 3. Get recovery recommendations for marathon training
        recovery_plan = await health_recovery_tools.get_recovery_recommendations_tool('general')
        assert "Recovery Recommendations" in recovery_plan
        
        # 4. Analyze race readiness 4 weeks out
        readiness = await competition_racing_tools.analyze_race_readiness_tool(
            26.2, '2024-11-03'
        )
        assert "Race Readiness Analysis" in readiness

    @pytest.mark.integration
    async def test_injury_prevention_scenario(self, realistic_user_setup):
        """Test injury prevention and recovery scenario."""
        
        mock_database = realistic_user_setup
        
        # Recent runs with concerning pattern
        concerning_runs = [
            {
                'distance': 15.0,
                'duration': '02:00:00',
                'date': datetime.now() - timedelta(days=1),
                'notes': 'Knee discomfort'
            },
            {
                'distance': 12.0,
                'duration': '01:36:00', 
                'date': datetime.now() - timedelta(days=2),
                'notes': 'Tight IT band'
            },
            {
                'distance': 8.0,
                'duration': '01:04:00',
                'date': datetime.now() - timedelta(days=3),
                'notes': 'Felt good'
            }
        ]
        
        mock_database.fetch.return_value = concerning_runs
        
        # 1. Analyze injury risk
        injury_risk = await health_recovery_tools.analyze_injury_risk_tool('2weeks')
        assert "Injury Risk Analysis" in injury_risk
        
        # 2. Get targeted recovery recommendations
        recovery_recs = await health_recovery_tools.get_recovery_recommendations_tool('legs')
        assert "Recovery Recommendations (Legs)" in recovery_recs
        
        # 3. Analyze training load for overuse patterns
        load_analysis = await health_recovery_tools.analyze_training_load_tool('4weeks')
        assert "Training Load Analysis" in load_analysis


# Pytest configuration for integration tests
if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short', '-m', 'integration'])